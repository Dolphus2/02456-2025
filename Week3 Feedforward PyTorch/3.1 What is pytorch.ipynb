{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "\n",
    "This is heavily based on https://github.com/pytorch/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is PyTorch?\n",
    "\n",
    "> **NOTE** In the last part of this lab cuda is used.\n",
    "\n",
    "\n",
    "PyTorch a Python based scientific computing package targeted at two sets of\n",
    "audiences:\n",
    "-  A replacement for numpy to use the power of GPUs\n",
    "-  a deep learning research platform that provides maximum flexibility and speed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "In this lab you will get a quick start on what pytorch is and how to use it.\n",
    "\n",
    "## 1. Tensors\n",
    "\n",
    "Tensors are similar to numpyâ€™s ndarrays, with the addition being that\n",
    "Tensors can also be used on a GPU to accelerate computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a $5\\times 3$ matrix, uninitialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-9.5211e+21,  9.3046e-43,  1.6631e+00],\n",
      "        [ 2.2467e+00,  2.6284e+00,  2.0963e+00],\n",
      "        [ 2.9041e+00,  2.1244e+00,  2.2797e+00],\n",
      "        [ 6.1976e-01,  9.7785e-01,  1.7196e-01],\n",
      "        [ 1.7235e+00,  2.5588e-01,  1.3227e+00]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a randomly initialized matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8830, 0.7305, 0.9080],\n",
      "        [0.9638, 0.9266, 0.8115],\n",
      "        [0.7248, 0.5449, 0.3061],\n",
      "        [0.6250, 0.2291, 0.0614],\n",
      "        [0.0259, 0.9459, 0.3089]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get its size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: `torch.Size` is in fact a tuple, so it supports the same operations that a tuple supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8830, 0.7305, 0.9080],\n",
      "        [2.0000, 2.0000, 2.0000],\n",
      "        [2.0000, 2.0000, 2.0000],\n",
      "        [0.6250, 0.2291, 0.0614],\n",
      "        [0.0259, 0.9459, 0.3089]])\n"
     ]
    }
   ],
   "source": [
    "x[1:3] = 2\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "Make use of the pytorch docs <http://pytorch.org/docs/torch>\n",
    "1. Make a tensor of size (2, 17)\n",
    "2. Make a torch.FloatTensor of size (3, 1)\n",
    "3. Make a torch.LongTensor of size (5, 2, 1)\n",
    "  - fill the entire tensor with 7s\n",
    "4. Make a torch.ByteTensor of size (5,)\n",
    "  - fill the middle 3 indices with ones such that it records [0, 1, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 17])\n",
      "torch.FloatTensor\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.FloatTensor\n",
      "torch.LongTensor\n",
      "tensor([0, 1, 1, 1, 0], dtype=torch.uint8)\n",
      "torch.ByteTensor\n",
      "torch.Size([5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.ones((2,17)).size())\n",
    "a = torch.ones((3,1))\n",
    "print(a.type())\n",
    "print(a.dtype)\n",
    "print(torch.get_default_dtype())\n",
    "print(a.type(torch.float).type())\n",
    "b = torch.full((5,2,1), 7)\n",
    "print(b.type(torch.int64).type())\n",
    "c = torch.zeros((5)).type(torch.uint8)\n",
    "c[1:4] = 1\n",
    "print(c)\n",
    "print(c.type())\n",
    "print(c.size())\n",
    "type((5,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Operations\n",
    "There are multiple syntaxes for operations. Let's see addition as an example:\n",
    "\n",
    "### 2.1 Addition: syntax 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1465, 1.6274, 1.0562],\n",
      "        [2.2829, 2.4803, 2.7131],\n",
      "        [2.7418, 2.4681, 2.6365],\n",
      "        [1.0016, 0.4388, 0.2895],\n",
      "        [0.5055, 1.1648, 1.0654]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Addition: syntax 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9561, 0.1569, 1.6631],\n",
      "        [2.2467, 2.6284, 2.0963],\n",
      "        [2.9041, 2.1244, 2.2797],\n",
      "        [0.6198, 0.9778, 0.1720],\n",
      "        [1.7235, 0.2559, 1.3227]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Addition: giving an output tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9561, 0.1569, 1.6631],\n",
      "        [2.2467, 2.6284, 2.0963],\n",
      "        [2.9041, 2.1244, 2.2797],\n",
      "        [0.6198, 0.9778, 0.1720],\n",
      "        [1.7235, 0.2559, 1.3227]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.Tensor(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Addition: in-place\n",
    "\n",
    "adds `x` to `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9561, 0.1569, 1.6631],\n",
      "        [2.2467, 2.6284, 2.0963],\n",
      "        [2.9041, 2.1244, 2.2797],\n",
      "        [0.6198, 0.9778, 0.1720],\n",
      "        [1.7235, 0.2559, 1.3227]])\n"
     ]
    }
   ],
   "source": [
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Any operation that mutates a tensor in-place is post-fixed with an `_`. For example: `x.copy_(y)`, `x.t_()`, will change `x`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use standard numpy-like indexing with all bells and whistles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7305, 2.0000, 2.0000, 0.2291, 0.9459])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read later**: 100+ Tensor operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random numbers, etc are described here <http://pytorch.org/docs/torch>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "1. multiplication of two tensors (see [torch.Tensor.mul](http://pytorch.org/docs/master/tensors.html#torch.Tensor.mul))\n",
    "2. do the same, but inplace\n",
    "3. division of two tensors (see [torch.Tensor.div](http://pytorch.org/docs/master/tensors.html#torch.Tensor.div))\n",
    "4. perform a matrix multiplication of two tensors of size (2, 4) and (4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "tensor([ 0,  1,  4,  9, 16])\n",
      "tensor([nan, 1., 1., 1., 1.])\n",
      "tensor([[28, 34],\n",
      "        [76, 98]])\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "x = torch.arange(5)\n",
    "y = torch.arange(5)\n",
    "print(torch.Tensor.mul(x,y))\n",
    "print(torch.Tensor.div(x,y))\n",
    "print(torch.Tensor.matmul(torch.arange(8).reshape(2,4), torch.arange(8).reshape(4,2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Numpy Bridge\n",
    "\n",
    "Converting a torch Tensor to a numpy array and vice versa is a breeze.\n",
    "\n",
    "The torch Tensor and numpy array will share their underlying memory locations, and changing one will change the other.\n",
    "\n",
    "### 3.1 Converting torch Tensor to numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the numpy array changed in value: the `numpy()` method provides a *view* of the original tensor, not a copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Converting numpy Array to torch Tensor\n",
    "\n",
    "See how changing the np array changed the torch Tensor automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "1. create a tensor of size (5, 2) containing ones\n",
    "2. now convert it to a NumPy array\n",
    "3. now convert it back to a torch tensor\n",
    "\n",
    "All the Tensors on the CPU except a CharTensor support converting to NumPy and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones((5,2)).numpy()\n",
    "print(type(a))\n",
    "torch.from_numpy(a).type()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 CUDA Tensors\n",
    "\n",
    "Tensors can be moved onto GPU using the `.cuda` function.\n",
    "This is not necessary, but check the `README.md` for details on how to use a GPU with docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0705, 0.0949, 0.9734],\n",
      "        [2.0000, 2.0000, 2.0000],\n",
      "        [2.0000, 2.0000, 2.0000],\n",
      "        [0.1682, 0.5153, 0.1253],\n",
      "        [0.7264, 0.1078, 0.7945]], device='cuda:0')\n",
      "tensor([[0.9561, 0.1569, 1.6631],\n",
      "        [2.2467, 2.6284, 2.0963],\n",
      "        [2.9041, 2.1244, 2.2797],\n",
      "        [0.6198, 0.9778, 0.1720],\n",
      "        [1.7235, 0.2559, 1.3227]], device='cuda:0')\n",
      "tensor([[1.0266, 0.2519, 2.6365],\n",
      "        [4.2467, 4.6284, 4.0963],\n",
      "        [4.9041, 4.1244, 4.2797],\n",
      "        [0.7880, 1.4932, 0.2972],\n",
      "        [2.4499, 0.3637, 2.1172]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = x + y\n",
    "    # Notice that the tensors are now of type torch.cuda.FloatTensor (notice the cuda in there)\n",
    "    # This is meant as a tensor to be run on the GPU.\n",
    "    # The .cuda() does this to any parameter it is applied to.\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(z)\n",
    "else:\n",
    "    print(\"CUDA not available on your machine.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
